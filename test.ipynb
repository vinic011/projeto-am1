{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto AM\n",
    "\n",
    "Alunos: Vinícius Pereira, Giuseppe Vicente, Nikolas Antes e Gustavo Beato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression  # Example model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explolaroty Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting cols that have more than one value\n",
    "- A maior partes das colunas é feita apenas de um valor (2000 colunas)\n",
    "- Isso não será útil para o treinamento, logo vamos descartar\n",
    "- Sobraram 1308 colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting cols that have more than one value\n",
    "util_cols = []\n",
    "for col in train.columns:\n",
    "    if train[col].value_counts().shape[0] < 2:\n",
    "        continue\n",
    "    else:\n",
    "        util_cols.append(col)\n",
    "\n",
    "train = train[util_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(util_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and fill NA values\n",
    "Fill feito com a média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()[train.isna().sum().values.astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.X1942.fillna(train.X1942.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find correlation inter features\n",
    "- Se faz primeiro o scaling das features para poder conseguir a matriz de covariância\n",
    "- Agrupam-se as features que possuem alta correlação (acima de 70%)\n",
    "- Selecionar-se uma feature de cada grupo de features, reduzindo dimensionalidade para 245 e evitando colunas altamente correlacionadas no treino, o que faz mal a alguns modelos como o KNN\n",
    "- Percebe-se que é possível determinar a classe através de algumas features com alta correlação\n",
    "\n",
    "\n",
    "![Alt text](/Users/viniciuspereira/Documents/ai/lorena/violon.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(train.drop(columns=[\"Class\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = pd.DataFrame(scaled_data, columns=train.drop(columns=[\"Class\"]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled[\"Class\"] = train[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs = abs(train_scaled.cov())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suponha que 'df' é o seu DataFrame com as features numéricas\n",
    "df = train_scaled\n",
    "\n",
    "corr_matrix = df.corr().abs()  # Usamos o valor absoluto da correlação\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "THRESHOLD = 0.7\n",
    "\n",
    "high_corr_pairs = [(column, index) for column in upper.columns for index in upper.index if not pd.isna(upper.loc[index, column]) and upper.loc[index, column] > THRESHOLD]\n",
    "\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(df.columns)\n",
    "G.add_edges_from(high_corr_pairs)\n",
    "\n",
    "# Encontrar os componentes conectados (grupos de features correlacionadas)\n",
    "groups = list(nx.connected_components(G))\n",
    "\n",
    "# Exibir os grupos\n",
    "print(\"\\nGrupos de features com alta correlação:\")\n",
    "for i, group in enumerate(groups, 1):\n",
    "    print(f\"Grupo {i}: {group}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_df = train_scaled[['X913','Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 6))\n",
    "# for class_value in principal_df[\"Class\"].unique():\n",
    "#     subset = principal_df[principal_df[\"Class\"] == class_value]\n",
    "#     plt.scatter( subset[\"Class\"],subset[\"X913\"], label=f'Class {class_value}', alpha=0.6)\n",
    "# plt.title(f'Histogram of {col} by Class')\n",
    "# plt.xlabel(col)\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.legend(title='Class')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.violin(principal_df, y=\"X913\", x=\"Class\", color=\"Class\", box=True, points=\"all\",\n",
    "          hover_data=principal_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_corr_cols = [list(group)[0] for group in groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(low_corr_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_high_corr = train_scaled[low_corr_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_high_corr['Id'] = train['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_high_corr['Class'] = train['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_high_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[low_corr_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns=[\"Id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [DecisionTreeClassifier(), KNeighborsClassifier(1), KNeighborsClassifier(3), KNeighborsClassifier(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [Pipeline([ ('scaler', StandardScaler()), ('model', model)]) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pipeline in pipelines:    \n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=skf)\n",
    "    pipeline.fit(X, y)\n",
    "    model = pipeline['model']\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(model.__class__.__name__)\n",
    "    if model.__class__.__name__ == \"KNeighborsClassifier\":\n",
    "        print(\"K:\", model.n_neighbors)\n",
    "    print(\"Stratified cross-validation scores:\", scores)\n",
    "    print(\"Mean stratified cross-validation score:\", scores.mean())\n",
    "    print(\"Standard deviation of stratified cross-validation score:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[low_corr_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns=[\"Id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []    \n",
    "for pipeline in pipelines:\n",
    "    pipeline.predict(test)\n",
    "    results.append(pipeline.predict_proba(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['Id'] = pd.read_csv('test.csv')['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[[\"Prob1\",\"Prob2\"]] = pd.DataFrame(results[2], columns=[\"Prob1\",\"Prob2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances =pd.DataFrame(index=test.columns,data =pipelines[0]['model'].feature_importances_, columns=[\"Feature Importance\"]).sort_values(by=\"Feature Importance\", ascending=False)\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicussões\n",
    "\n",
    "- Primeiramente, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
